import os
import re
import shutil
import subprocess
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

from funasr import AutoModel


# ---------------------------
# åŸºç¡€å·¥å…·
# ---------------------------

def run_cmd(cmd: List[str]) -> str:
    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    if p.returncode != 0:
        raise RuntimeError(
            f"Command failed: {' '.join(cmd)}\n\nSTDOUT:\n{p.stdout}\n\nSTDERR:\n{p.stderr}"
        )
    return p.stdout.strip()


def ffprobe_duration_sec(media_path: str) -> float:
    out = run_cmd([
        "ffprobe", "-v", "error",
        "-show_entries", "format=duration",
        "-of", "default=noprint_wrappers=1:nokey=1",
        media_path
    ])
    return float(out)


def extract_audio_wav_16k_mono(input_video: str, wav_out: str) -> None:
    # å¼ºåˆ¶ï¼š16k / mono / pcm_s16leï¼Œæœ€å¤§é™åº¦é¿å…æ—¶é—´æ¼‚ç§»
    run_cmd([
        "ffmpeg", "-y",
        "-i", input_video,
        "-vn",
        "-ac", "1",
        "-ar", "16000",
        "-sample_fmt", "s16",
        "-c:a", "pcm_s16le",
        wav_out
    ])


def srt_time(ms: int) -> str:
    if ms < 0:
        ms = 0
    hh = ms // 3600000
    mm = (ms % 3600000) // 60000
    ss = (ms % 60000) // 1000
    mmm = ms % 1000
    return f"{hh:02d}:{mm:02d}:{ss:02d},{mmm:03d}"


def norm_text(s: str) -> str:
    s = (s or "").strip()
    s = re.sub(r"\s+", " ", s)
    return s


@dataclass
class Segment:
    start_ms: int
    end_ms: int
    text: str


def write_srt(segs: List[Segment], out_srt: str) -> None:
    lines = []
    for i, seg in enumerate(segs, 1):
        lines.append(str(i))
        lines.append(f"{srt_time(seg.start_ms)} --> {srt_time(seg.end_ms)}")
        lines.append(seg.text)
        lines.append("")
    with open(out_srt, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))


# ---------------------------
# æ ¸å¿ƒï¼šä» FunASR è¾“å‡ºæ‹¿åˆ°â€œå¥çº§æ—¶é—´æˆ³â€
# ---------------------------

def funasr_to_segments(res: Any, audio_dur_sec: float) -> List[Segment]:
    """
    ç›®æ ‡ï¼šä¼˜å…ˆä½¿ç”¨ res[0]['sentence_info']ï¼Œé‡Œé¢æ¯å¥éƒ½æœ‰ start/end(ms)
    è¿™æ˜¯ç”Ÿæˆ FCPX å¯ç”¨å­—å¹•çš„æœ€ç¨³æ–¹å¼ã€‚
    """
    audio_ms = int(round(audio_dur_sec * 1000))

    if not isinstance(res, list) or len(res) == 0 or not isinstance(res[0], dict):
        raise RuntimeError(f"Unexpected FunASR result format: {type(res)}")

    r0 = res[0]
    sentences = r0.get("sentence_info", None)

    if not sentences:
        # æ²¡ sentence_info çš„è¯ï¼ŒåŸºæœ¬å°±æ— æ³•ä¿è¯é€å¥ç²¾å‡†å¯¹é½
        # ç›´æ¥æŠ›é”™ï¼Œé€¼ä½ ä¿®å‚æ•°ï¼ˆæ¯”é™é»˜ç”Ÿæˆ 1 æ¡å­—å¹•é è°±å¤ªå¤šï¼‰
        raise RuntimeError(
            "FunASR result has NO sentence_info.\n"
            "ä½ éœ€è¦åœ¨ AutoModel åˆå§‹åŒ–æ—¶è®¾ç½® sentence_timestamp=Trueã€‚"
        )

    segs: List[Segment] = []
    for s in sentences:
        if not isinstance(s, dict):
            continue
        # text = norm_text(s.get("text", ""))
        text = strip_trailing_punc(norm_text(s.get("text", "")))

        if not text:
            continue

        # FunASR çš„ sentence_info çš„ start/end é€šå¸¸æ˜¯ msï¼ˆå¾ˆå¤šç¤ºä¾‹éƒ½è¿™ä¹ˆç”¨ï¼‰:contentReference[oaicite:1]{index=1}
        st = int(s.get("start", 0))
        ed = int(s.get("end", 0))

        # å¥å£®æ€§ä¿®æ­£
        if ed <= st:
            ed = st + 400
        if st < 0:
            st = 0
        if ed > audio_ms:
            ed = audio_ms

        segs.append(Segment(st, ed, text))

    # å¼ºåˆ¶å•è°ƒé€’å¢ï¼ˆé¿å… FCPX æŸäº›æƒ…å†µä¸‹å¯¼å…¥å¼‚å¸¸ï¼‰
    segs.sort(key=lambda x: (x.start_ms, x.end_ms))
    fixed: List[Segment] = []
    last_end = 0
    for seg in segs:
        if seg.start_ms < last_end:
            seg.start_ms = last_end
        if seg.end_ms <= seg.start_ms:
            seg.end_ms = min(seg.start_ms + 400, audio_ms)
        fixed.append(seg)
        last_end = seg.end_ms

    # æœ€åä¸€æ¡æ‹‰åˆ°éŸ³é¢‘æœ«å°¾ä¸€ç‚¹ï¼Œé¿å…â€œå°¾å·´è¢«æˆªæ–­â€
    if fixed and audio_ms - fixed[-1].end_ms >= 800:
        fixed[-1].end_ms = audio_ms

    return fixed

def strip_trailing_punc(text: str) -> str:
    """
    åªå»æ‰å¥å°¾æ ‡ç‚¹ï¼Œä¸å½±å“å¥ä¸­å†…å®¹ã€‚
    ä¾‹å¦‚ï¼š
      "ä½ å¥½ã€‚" -> "ä½ å¥½"
      "OK!" -> "OK"
      "çœŸçš„å—ï¼Ÿï¼" -> "çœŸçš„å—"
      "test..." -> "test"
    """
    if not text:
        return text

    # å¥å°¾å¯èƒ½å‡ºç°çš„ä¸­è‹±æ–‡æ ‡ç‚¹ï¼ˆå¯æŒ‰éœ€å¢åˆ ï¼‰
    trailing = "ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€,.!?;:~â€¦â€”-Â·\"'ï¼‰)ã€‘]ã€‹>ã€‹"
    t = text.rstrip()

    # è¿ç»­å‰”é™¤æœ«å°¾æ ‡ç‚¹
    while t and t[-1] in trailing:
        t = t[:-1].rstrip()

    return t


# ---------------------------
# ä¸»æµç¨‹
# ---------------------------

def m4v_to_srt(input_video: str, out_srt: str, tmp_dir: str = ".") -> None:
    if shutil.which("ffmpeg") is None or shutil.which("ffprobe") is None:
        raise RuntimeError("ffmpeg / ffprobe not found. Please install ffmpeg first.")

    if not os.path.exists(input_video):
        raise FileNotFoundError(input_video)

    base = os.path.splitext(os.path.basename(input_video))[0]
    tmp_wav = os.path.join(tmp_dir, f"{base}__16k.wav")

    # 1) æŠ½éŸ³é¢‘ï¼ˆæ ‡å‡†åŒ–ï¼‰
    extract_audio_wav_16k_mono(input_video, tmp_wav)

    # 2) æ—¶é•¿
    audio_dur_sec = ffprobe_duration_sec(tmp_wav)

   

    # 3) å…³é”®ç‚¹ï¼šsentence_timestamp=True è®©è¿”å›ç»“æœåŒ…å« sentence_info
    model = AutoModel(
        model="paraformer-zh",
        # model="damo/speech_paraformer-large-contextual_asr_nat-zh-cn-16k-common-vocab8404",
        vad_model="fsmn-vad",
        punc_model="damo/punc_ct-transformer_cn-en-common-vocab471067-large",
        sentence_timestamp=True,      # âœ… å…³é”®å¼€å…³ï¼šé€å¥æ—¶é—´æˆ³
        return_raw_text=False
    )

    hotwords = [
        "Action6", "Action5", "DLOGM"
    ]
    res = model.generate(input=tmp_wav, batch_size_s=300, hotword=" ".join(hotwords))

    segments = funasr_to_segments(res, audio_dur_sec)
    write_srt(segments, out_srt)

    print(f"âœ… Done: {out_srt}")


if __name__ == "__main__":
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    input_dir = os.path.join(script_dir, "input")
    output_dir = os.path.join(script_dir, "output")
    
    # ç¡®ä¿ input å’Œ output æ–‡ä»¶å¤¹å­˜åœ¨
    if not os.path.exists(input_dir):
        print(f"âŒ Error: input directory not found: {input_dir}")
        exit(1)
    
    os.makedirs(output_dir, exist_ok=True)
    
    # æ”¯æŒçš„è§†é¢‘æ ¼å¼
    video_exts = ('.mp4', '.mov', '.m4v')
    
    # æ‰«æ input æ–‡ä»¶å¤¹
    video_files = []
    for fname in os.listdir(input_dir):
        if fname.lower().endswith(video_exts):
            video_files.append(os.path.join(input_dir, fname))
    
    if not video_files:
        print(f"âš ï¸  No video files found in {input_dir}")
        print(f"   Supported formats: {', '.join(video_exts)}")
        exit(0)
    
    print(f"Found {len(video_files)} video file(s) to process:")
    for vf in video_files:
        print(f"  - {os.path.basename(vf)}")
    print()
    
    # æ‰¹é‡å¤„ç†
    for video_path in video_files:
        base_name = os.path.splitext(os.path.basename(video_path))[0]
        out_srt = os.path.join(output_dir, f"{base_name}.srt")
        
        print(f"Processing: {os.path.basename(video_path)}...")
        try:
            m4v_to_srt(video_path, out_srt, tmp_dir=output_dir)
        except Exception as e:
            print(f"âŒ Failed to process {os.path.basename(video_path)}: {e}")
            continue
    
    print(f"\nğŸ‰ All done! Check {output_dir} for results.")
